{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6485e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas for reading and analyzing data\n",
    "import pandas as pd\n",
    "# numpy for numerical calcuations\n",
    "import numpy as np\n",
    "# os to find path of files \n",
    "import os\n",
    "\n",
    "# tensorflow as machine learning library\n",
    "import tensorflow as tf\n",
    "# keras as open-source deep-learning library \n",
    "from tensorflow import keras\n",
    "# building blocks of NN in Keras\n",
    "from tensorflow.keras import layers\n",
    "# earlyStop to stop training early\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# IPython to Clear terminal output\n",
    "import IPython\n",
    "import IPython.display\n",
    "\n",
    "# pickle to save dictionary in file\n",
    "import pickle \n",
    "# time and timeit to provie a callback to logg model fitting time\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# helper functions\n",
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "cwd = os.path.normpath(os.getcwd()+ os.sep + os.pardir+ os.sep + os.pardir)\n",
    "sys.path.insert(1, cwd + \"/src/d00_utils\") \n",
    "from federated_helper_functions import *\n",
    "from model_helper_functions import *\n",
    "from windowgenerator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a1a7b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCompileEvaluateModel(path, window, MAX_EPOCHS):\n",
    "    \"\"\"\n",
    "    load model, compile and evaluate on test window  \n",
    "    \n",
    "    :param: model path and window\n",
    "    \"\"\"           \n",
    "    model = tf.keras.models.load_model(path)\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError(), \n",
    "            tf.keras.metrics.MeanAbsolutePercentageError(),\n",
    "            tf.keras.metrics.MeanAbsoluteError(),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    #fit local model with client's data\n",
    "    model.fit(\n",
    "        window.train, \n",
    "        epochs=MAX_EPOCHS, \n",
    "        verbose=1, \n",
    "        validation_data=window.val,\n",
    "        callbacks=[\n",
    "            timetaken,\n",
    "            #early_stopping, \n",
    "            #create_model_checkpoint(save_path=save_path), \n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    model_evaluation_test = model.evaluate(window.test)\n",
    "    return model_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be23a66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data\n",
      "Selected clients:  33\n",
      "Clustered clients:  [2 2 4 4 1 5 1 5 1 5 5 5 5 1 3 0 3 0 5 1 3 3 3 3 5 2 2 1 3 0 0 1 2]\n",
      "Created dictionary with datasets\n",
      "Created Data windows\n",
      "{4: {'client_3_0141-ZE01-70': [Total window size: 36\n",
      "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "Label indices: [24 25 26 27 28 29 30 31 32 33 34 35]\n",
      "Label column name(s): ['0141-ZE01-70'], Total window size: 48\n",
      "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "Label indices: [24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "Label column name(s): ['0141-ZE01-70'], Total window size: 36\n",
      "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "Label indices: [24 25 26 27 28 29 30 31 32 33 34 35]\n",
      "Label column name(s): ['0141-ZE01-70'], Total window size: 48\n",
      "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "Label indices: [24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "Label column name(s): ['0141-ZE01-70']], 'client_4_0141-ZE01-74': [Total window size: 36\n",
      "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "Label indices: [24 25 26 27 28 29 30 31 32 33 34 35]\n",
      "Label column name(s): ['0141-ZE01-74'], Total window size: 48\n",
      "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "Label indices: [24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "Label column name(s): ['0141-ZE01-74'], Total window size: 36\n",
      "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "Label indices: [24 25 26 27 28 29 30 31 32 33 34 35]\n",
      "Label column name(s): ['0141-ZE01-74'], Total window size: 48\n",
      "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "Label indices: [24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "Label column name(s): ['0141-ZE01-74']]}}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter\n",
    "OUT_STEPS = [12, 24] #Next 12 or 24 hours\n",
    "INPUT_STEPS = 24\n",
    "#Training epochs\n",
    "MAX_EPOCHS = 2\n",
    "\n",
    "#Data Analytics\n",
    "print(\"Get data\")\n",
    "# get current working directory and go back one folder to main working directory\n",
    "cwd = os.path.normpath(os.getcwd()+ os.sep + os.pardir+ os.sep + os.pardir)\n",
    "#Read CSV file to pandas dataframe; encoding= 'unicode_escape': Decode from Latin-1 source code. Default UTF-8.\n",
    "df = pd.read_csv(cwd+'/data/d03_data_processed/d03_data_processed.csv', encoding= 'unicode_escape', index_col='Date')\n",
    "#Display smart meter names and amount\n",
    "smart_meter_names = df.columns[2:-4]\n",
    "print(\"Selected clients: \", len(smart_meter_names))\n",
    "\n",
    "#Get clustered clients\n",
    "N_CLUSTERS = 6\n",
    "y = np.loadtxt(cwd+'/data/d04_clients_clustered/d04_clients_clustered.csv', delimiter=',').astype(int)\n",
    "print(\"Clustered clients: \", y)\n",
    "\n",
    "# Make Datasets for the 33 clients and for 5 and 7 features\n",
    "ds_dict = makeDatasetsForclientsAndfeatures(smart_meter_names, df)\n",
    "print(\"Created dictionary with datasets\")\n",
    "\n",
    "# Create Windows \n",
    "windows_dict = createDataWindows(y, smart_meter_names, INPUT_STEPS, OUT_STEPS, ds_dict, N_CLUSTERS)\n",
    "print(\"Created Data windows\")\n",
    "\n",
    "windows_dict = {k: v for k, v in windows_dict.items() if k == 4}\n",
    "print(windows_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93189997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster---- 4 ----- client_4_0141-ZE01-74 -------- 2 / 2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/2\n",
      "575/575 [==============================] - 77s 118ms/step - loss: 0.0602 - root_mean_squared_error: 0.2455 - mean_absolute_percentage_error: 65008864.0000 - mean_absolute_error: 0.1973 - val_loss: 0.0326 - val_root_mean_squared_error: 0.1806 - val_mean_absolute_percentage_error: 72346656.0000 - val_mean_absolute_error: 0.1542\n",
      "Epoch 2/2\n",
      "575/575 [==============================] - 64s 111ms/step - loss: 0.0567 - root_mean_squared_error: 0.2381 - mean_absolute_percentage_error: 62986664.0000 - mean_absolute_error: 0.1895 - val_loss: 0.0281 - val_root_mean_squared_error: 0.1675 - val_mean_absolute_percentage_error: 64742040.0000 - val_mean_absolute_error: 0.1331\n",
      "82/82 [==============================] - 3s 32ms/step - loss: 0.0341 - root_mean_squared_error: 0.1847 - mean_absolute_percentage_error: 79214488.0000 - mean_absolute_error: 0.1531\n",
      "Saved LSTM\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/2\n",
      "575/575 [==============================] - 6s 7ms/step - loss: 0.0319 - root_mean_squared_error: 0.1787 - mean_absolute_percentage_error: 48392656.0000 - mean_absolute_error: 0.1319 - val_loss: 0.0315 - val_root_mean_squared_error: 0.1776 - val_mean_absolute_percentage_error: 73479328.0000 - val_mean_absolute_error: 0.1403\n",
      "Epoch 2/2\n",
      "575/575 [==============================] - 4s 6ms/step - loss: 0.0311 - root_mean_squared_error: 0.1764 - mean_absolute_percentage_error: 48074992.0000 - mean_absolute_error: 0.1300 - val_loss: 0.0310 - val_root_mean_squared_error: 0.1761 - val_mean_absolute_percentage_error: 71501624.0000 - val_mean_absolute_error: 0.1395\n",
      "82/82 [==============================] - 0s 2ms/step - loss: 0.0351 - root_mean_squared_error: 0.1872 - mean_absolute_percentage_error: 83625192.0000 - mean_absolute_error: 0.1538\n",
      "Saved CNN\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/2\n",
      "575/575 [==============================] - 44s 59ms/step - loss: 0.0385 - root_mean_squared_error: 0.1963 - mean_absolute_percentage_error: 52375656.0000 - mean_absolute_error: 0.1472 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1496 - val_mean_absolute_percentage_error: 62110852.0000 - val_mean_absolute_error: 0.1141\n",
      "Epoch 2/2\n",
      "575/575 [==============================] - 32s 56ms/step - loss: 0.0369 - root_mean_squared_error: 0.1920 - mean_absolute_percentage_error: 51235404.0000 - mean_absolute_error: 0.1426 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1487 - val_mean_absolute_percentage_error: 61739200.0000 - val_mean_absolute_error: 0.1132\n",
      "82/82 [==============================] - 1s 15ms/step - loss: 0.0280 - root_mean_squared_error: 0.1674 - mean_absolute_percentage_error: 75533384.0000 - mean_absolute_error: 0.1319\n",
      "Saved Transformer\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'final_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 58\u001b[0m\n\u001b[0;32m     52\u001b[0m         forecasts_dict_Transformer_F5_H12[cluster][client] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     53\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSE\u001b[39m\u001b[38;5;124m'\u001b[39m:model_evaluation_test[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m:model_evaluation_test[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAPE\u001b[39m\u001b[38;5;124m'\u001b[39m:model_evaluation_test[\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m     54\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m'\u001b[39m:model_evaluation_test[\u001b[38;5;241m3\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m:((timetaken\u001b[38;5;241m.\u001b[39mlogs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m (timetaken\u001b[38;5;241m.\u001b[39mlogs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)) \n\u001b[0;32m     55\u001b[0m         }\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved Transformer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m \u001b[43mfinal_dict\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFederated\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH12\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF5\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m forecasts_dict_LSTM_F5_H12\n\u001b[0;32m     59\u001b[0m final_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFederated\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNN\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH12\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF5\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m forecasts_dict_CNN_F5_H12\n\u001b[0;32m     60\u001b[0m final_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFederated\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransformer\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH12\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF5\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m forecasts_dict_Transformer_F5_H12\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_dict' is not defined"
     ]
    }
   ],
   "source": [
    "#Evaluate Results\n",
    "forecasts_dict_LSTM_F5_H12 = {k: {} for k in range(N_CLUSTERS)}\n",
    "forecasts_dict_CNN_F5_H12 = {k: {} for k in range(N_CLUSTERS)}\n",
    "forecasts_dict_Transformer_F5_H12 = {k: {} for k in range(N_CLUSTERS)}\n",
    "\n",
    "last_fedeated_round = 1\n",
    "\n",
    "for idx, cluster in enumerate(windows_dict):\n",
    "    \n",
    "    #Get names of clients within cluster\n",
    "    client_names = list()\n",
    "    for client in windows_dict[cluster]:\n",
    "        client_names.append(client)\n",
    "\n",
    "    for i, client in enumerate(windows_dict[cluster].keys()):\n",
    "        IPython.display.clear_output()\n",
    "        print(\"Cluster----\", cluster, \"-----\", client,\"--------\", i+1, \"/\", len(client_names))     \n",
    "        \n",
    "        #LSTM\n",
    "        model_evaluation_test = loadCompileEvaluateModel(\n",
    "            path = cwd + f\"/data/d05_models/cluster{idx}/Federated_LSTM_F5_H12/FederatedRound{last_fedeated_round}\",\n",
    "            window = windows_dict[cluster][client][0], \n",
    "            MAX_EPOCHS = MAX_EPOCHS\n",
    "        )\n",
    "        #Save\n",
    "        forecasts_dict_LSTM_F5_H12[cluster][client] = {\n",
    "            'MSE':model_evaluation_test[0], 'RMSE':model_evaluation_test[1], 'MAPE':model_evaluation_test[2],\n",
    "            'MAE':model_evaluation_test[3], 'Time':((timetaken.logs[-1][1]) / (timetaken.logs[-1][0]+1)) \n",
    "        }\n",
    "        print(\"Saved LSTM\")\n",
    "        \n",
    "        #CNN\n",
    "        model_evaluation_test = loadCompileEvaluateModel(\n",
    "            path = cwd + f\"/data/d05_models/cluster{idx}/Federated_CNN_F5_H12/FederatedRound{last_fedeated_round}\",\n",
    "            window = windows_dict[cluster][client][0], \n",
    "            MAX_EPOCHS = MAX_EPOCHS\n",
    "        )\n",
    "        #Save\n",
    "        forecasts_dict_CNN_F5_H12[cluster][client] = {\n",
    "            'MSE':model_evaluation_test[0], 'RMSE':model_evaluation_test[1], 'MAPE':model_evaluation_test[2],\n",
    "            'MAE':model_evaluation_test[3], 'Time':((timetaken.logs[-1][1]) / (timetaken.logs[-1][0]+1)) \n",
    "        }    \n",
    "        print(\"Saved CNN\")\n",
    "        \n",
    "        #Transformer\n",
    "        model_evaluation_test = loadCompileEvaluateModel(\n",
    "            path = cwd + f\"/data/d05_models/cluster{idx}/Federated_Transformer_F5_H12/FederatedRound{last_fedeated_round}\",\n",
    "            window = windows_dict[cluster][client][0], \n",
    "            MAX_EPOCHS = MAX_EPOCHS\n",
    "        )\n",
    "        #Save\n",
    "        forecasts_dict_Transformer_F5_H12[cluster][client] = {\n",
    "            'MSE':model_evaluation_test[0], 'RMSE':model_evaluation_test[1], 'MAPE':model_evaluation_test[2],\n",
    "            'MAE':model_evaluation_test[3], 'Time':((timetaken.logs[-1][1]) / (timetaken.logs[-1][0]+1)) \n",
    "        }\n",
    "        print(\"Saved Transformer\")\n",
    "\n",
    "#Inintialize result dictionary\n",
    "final_dict = InititalizeResultDictionary(learning_style=\"Federated\")\n",
    "final_dict['Federated']['LSTM']['H12']['F5'] = forecasts_dict_LSTM_F5_H12\n",
    "final_dict['Federated']['CNN']['H12']['F5'] = forecasts_dict_CNN_F5_H12\n",
    "final_dict['Federated']['Transformer']['H12']['F5'] = forecasts_dict_Transformer_F5_H12\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cwd + '/results/Federated_results_H12_F5.pkl', 'wb') as f:\n",
    "    pickle.dump(final_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
