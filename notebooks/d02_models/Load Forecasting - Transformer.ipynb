{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e740ff02",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48af0601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.util.tf_export import keras_export\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Attention\n",
    "from tensorflow.keras.layers import GRU,Dense,Input,TimeDistributed,RepeatVector\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "from timeseries_preprocessing import *\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "#from specnorm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aecf07",
   "metadata": {},
   "source": [
    "### Data import and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa60fb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rs1044\\AppData\\Local\\Temp\\ipykernel_19504\\4254567175.py:2: DtypeWarning: Columns (2,3,4,5,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(\"Data/household_power_consumption.txt\",delimiter=\";\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:00:00</th>\n",
       "      <td>0.577718</td>\n",
       "      <td>0.613331</td>\n",
       "      <td>0.326483</td>\n",
       "      <td>0.579554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>0.677366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:30:00</th>\n",
       "      <td>0.521563</td>\n",
       "      <td>0.225564</td>\n",
       "      <td>0.338921</td>\n",
       "      <td>0.522275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>0.678707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 18:00:00</th>\n",
       "      <td>0.495215</td>\n",
       "      <td>0.107544</td>\n",
       "      <td>0.357066</td>\n",
       "      <td>0.498011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187397</td>\n",
       "      <td>0.682731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 18:30:00</th>\n",
       "      <td>0.414938</td>\n",
       "      <td>0.095294</td>\n",
       "      <td>0.311864</td>\n",
       "      <td>0.416468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033425</td>\n",
       "      <td>0.674683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 19:00:00</th>\n",
       "      <td>0.433530</td>\n",
       "      <td>0.063107</td>\n",
       "      <td>0.303577</td>\n",
       "      <td>0.431782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030137</td>\n",
       "      <td>0.674683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power   Voltage  \\\n",
       "datetime                                                                    \n",
       "2006-12-16 17:00:00             0.577718               0.613331  0.326483   \n",
       "2006-12-16 17:30:00             0.521563               0.225564  0.338921   \n",
       "2006-12-16 18:00:00             0.495215               0.107544  0.357066   \n",
       "2006-12-16 18:30:00             0.414938               0.095294  0.311864   \n",
       "2006-12-16 19:00:00             0.433530               0.063107  0.303577   \n",
       "\n",
       "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
       "datetime                                                                \n",
       "2006-12-16 17:00:00          0.579554             0.0        0.021918   \n",
       "2006-12-16 17:30:00          0.522275             0.0        0.006027   \n",
       "2006-12-16 18:00:00          0.498011             0.0        0.187397   \n",
       "2006-12-16 18:30:00          0.416468             0.0        0.033425   \n",
       "2006-12-16 19:00:00          0.431782             0.0        0.030137   \n",
       "\n",
       "                     Sub_metering_3  \n",
       "datetime                             \n",
       "2006-12-16 17:00:00        0.677366  \n",
       "2006-12-16 17:30:00        0.678707  \n",
       "2006-12-16 18:00:00        0.682731  \n",
       "2006-12-16 18:30:00        0.674683  \n",
       "2006-12-16 19:00:00        0.674683  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get Data\n",
    "df1 = pd.read_csv(\"Data/household_power_consumption.txt\",delimiter=\";\")\n",
    "\n",
    "#Format Data\n",
    "df1[\"datetime\"] = df1[[\"Date\",\"Time\"]].apply(lambda x: x[0]+\" \"+x[1],axis=1)\n",
    "df1[\"datetime\"] = pd.to_datetime(df1[\"datetime\"], infer_datetime_format=True)\n",
    "df1 = df1.drop([\"Date\",\"Time\"],axis=1)\n",
    "df1.index = df1[\"datetime\"]\n",
    "df1 = df1.drop(\"datetime\",axis=1)\n",
    "df1 = df1.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "\n",
    "#Preprocess Data\n",
    "#Fill NaN values in a smart way\n",
    "df1 = df1.interpolate()\n",
    "#resample\n",
    "df2 = df1.resample('30T').mean()\n",
    "df2 = df2.interpolate()\n",
    "#numpy array of values per column\n",
    "df2_data = df2.values\n",
    "#Scale values (x-min/max-min)\n",
    "scaler = MinMaxScaler()\n",
    "#Alternative: fit_transform(df2_data)\n",
    "#fit: Compute the minimum and maximum to be used for later scaling.\n",
    "scaler.fit(df2_data)\n",
    "#transform: Scale features of X according to feature_range.\n",
    "df2_data = scaler.transform(df2_data)\n",
    "\n",
    "for i,name in enumerate(df2.columns):\n",
    "    df2[name] = df2_data[:,i]\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14817bff",
   "metadata": {},
   "source": [
    "### Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e95149dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsample_length: [day, week, month]\\nepochs [200]\\nbatch size: 32, 64, 256, 1024, 2048]\\n\\nencoder_layers [1,2,3,4,5,6]\\ndecoder_layers [1,2,3,4,5,6]\\nd_model [32, 64, 128, 256]\\ndff [512]\\nnum_heads [8]\\ndropout_rate [0.1]\\n\\n{\\n  \"per_gpu_batch_size\": [16, 32],\\n  \"learning_rate\": [2e-5, 3e-5, 5e-5],\\n  \"num_epochs\": [2, 3, 4]\\n}\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#24 historical samples will predict the future samples\n",
    "sample_length = 24\n",
    "\n",
    "epochs=20\n",
    "\n",
    "batch_size = 256\n",
    "num_encoder_layers = 4\n",
    "num_decoder_layers = 4\n",
    "d_model = 32\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate=0.1\n",
    "\n",
    "\"\"\"\n",
    "sample_length: [day, week, month]\n",
    "epochs [200]\n",
    "batch size: 32, 64, 256, 1024, 2048]\n",
    "\n",
    "encoder_layers [1,2,3,4,5,6]\n",
    "decoder_layers [1,2,3,4,5,6]\n",
    "d_model [32, 64, 128, 256]\n",
    "dff [512]\n",
    "num_heads [8]\n",
    "dropout_rate [0.1]\n",
    "\n",
    "{\n",
    "  \"per_gpu_batch_size\": [16, 32],\n",
    "  \"learning_rate\": [2e-5, 3e-5, 5e-5],\n",
    "  \"num_epochs\": [2, 3, 4]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29818721",
   "metadata": {},
   "source": [
    "### Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71b567de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(filename= \"img/train-test-split.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c0e8d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split arrays or matrices into random train and test subsets.\n",
    "-> From the features in array 1 we predict the columns of array2\n",
    "array1: df2.iloc[:,:-3] (Global active power, Voltage, Global reactive power, global intensity)\n",
    "array2: df2.iloc[:,-3:] (Submetering 1-3)\n",
    "test_size: proportion of the dataset to include in the test split (often 0.30)\n",
    "shuffle: False -> preserve the sequential information (True -> scramble rows and destroy temporal information)\n",
    "\"\"\"\n",
    "#Features: X_train and X_test are used to forecast target: y_train and y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df2.iloc[:,:-3].values, df2.iloc[:,-3:].values, test_size=0.05,shuffle=False)\n",
    "# Casts a tensor to a new type.\n",
    "data = tf.cast(X_train,tf.float32)\n",
    "targets = tf.cast(y_train,tf.float32)\n",
    "\n",
    "#Creates a dataset of sliding windows over a timeseries provided as array.\n",
    "\"\"\"\n",
    "data: Numpy array or tensor containing consecutive data points. Axis 0 is expected to be the time dimension.\n",
    "targets: Targets corresponding to timesteps in data. Pass None if you don't have target data.\n",
    "sequence_length: Length of the output sequences (in number of timesteps).\n",
    "sequence_stride: Period between successive output sequences. For stride s, \n",
    "    output samples would start at index data[i], data[i + s], data[i + 2 * s], etc\n",
    "sampling_rate: eriod between successive individual timesteps within sequences. For rate r, \n",
    "    timesteps data[i], data[i + r], ... data[i + sequence_length] are used for creating a sample sequence.\n",
    "batch_size: Number of timeseries samples in each batch (except maybe the last one). If None, \n",
    "    the data will not be batched (the dataset will yield individual samples).\n",
    "\"\"\"\n",
    "#24 historical samples (sample_length) of the first 4 columns (data/ features) \n",
    "#will predict the future 6 samples (output_seqeunce_length) of the last 3 columns (target)\n",
    "input_dataset = timeseries_dataset_from_array(\n",
    "    data,\n",
    "    None, \n",
    "    sequence_length=sample_length,\n",
    "    batch_size=batch_size, \n",
    "    sequence_stride=sample_length\n",
    ")\n",
    "target_dataset = timeseries_dataset_from_array(\n",
    "    targets, \n",
    "    None, \n",
    "    sequence_length=6,\n",
    "    batch_size=batch_size, \n",
    "    sequence_stride=sample_length\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eee3b9",
   "metadata": {},
   "source": [
    "### Building the Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25faaaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "@tf.function\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "\n",
    "def create_masks(inp, tar):\n",
    "  # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "  # Used in the 2nd attention block in the decoder.\n",
    "  # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by\n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "\n",
    "@tf.function  \n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead)\n",
    "    but it must be broadcastable for addition.\n",
    "\n",
    "    Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable\n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    # dk = k.get_shape().as_list()[-1]\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads,spec_norm=False):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.kernel_init = tf.keras.initializers.Orthogonal()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        if spec_norm:\n",
    "            self.spec_norm = SpectralNormalization\n",
    "        else:\n",
    "            self.spec_norm = lambda x: x\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = self.spec_norm(tf.keras.layers.Dense(d_model,kernel_initializer=self.kernel_init))\n",
    "        self.wk = self.spec_norm(tf.keras.layers.Dense(d_model,kernel_initializer=self.kernel_init))\n",
    "        self.wv = self.spec_norm(tf.keras.layers.Dense(d_model,kernel_initializer=self.kernel_init))\n",
    "\n",
    "        self.dense = self.spec_norm(tf.keras.layers.Dense(d_model,kernel_initializer=self.kernel_init))\n",
    "        # self.attn_layer = Attention(use_scale=True)\n",
    "        \n",
    "    @tf.function   \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention= scaled_dot_product_attention(q, k, v, mask)\n",
    "        # scaled_attention = self.attn_layer([q,v,k],[mask,None])\n",
    "        # attention_weights = None\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output\n",
    "    \n",
    "def point_wise_feed_forward_network(d_model, dff,spec_norm=False):\n",
    "    if spec_norm:\n",
    "        wrapper = SpectralNormalization\n",
    "    else:\n",
    "        wrapper = lambda x: x\n",
    "    kernel_init = tf.keras.initializers.Orthogonal()\n",
    "    return tf.keras.Sequential([\n",
    "      wrapper(tf.keras.layers.Dense(dff, activation='relu',kernel_initializer=kernel_init)),  # (batch_size, seq_len, dff)\n",
    "      wrapper(tf.keras.layers.Dense(d_model,kernel_initializer=kernel_init))  # (batch_size, seq_len, d_model)\n",
    "    ])\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1,spec_norm=False):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.spec_norm = spec_norm\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads,self.spec_norm)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff,self.spec_norm)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "         \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2\n",
    "    \n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1= self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2 = self.mha2(enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3\n",
    "    \n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, rate=0.1,spec_norm=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        if spec_norm:\n",
    "            self.spec_norm = SpectralNormalization\n",
    "        else:\n",
    "            self.spec_norm = lambda x: x\n",
    "\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = TimeDistributed(self.spec_norm(tf.keras.layers.Dense(d_model,kernel_initializer = tf.keras.initializers.Orthogonal())))\n",
    "        \n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate,spec_norm) for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.n_timesteps = input_shape.as_list()[1]\n",
    "        self.pos_encoding = positional_encoding(self.n_timesteps, self.d_model)\n",
    "           \n",
    "    def transform(self,x):\n",
    "        seq_len = x.get_shape().as_list()[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        # x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x = x * np.sqrt(self.d_model)\n",
    "        x = x + self.pos_encoding[:, :seq_len, :]\n",
    "        return x\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        # seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        # x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        # x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        # x = x * np.sqrt(self.d_model)\n",
    "        # x = x + self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.transform(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = TimeDistributed(tf.keras.layers.Dense(d_model,kernel_initializer = tf.keras.initializers.Orthogonal()))\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.n_timesteps = input_shape.as_list()[1]\n",
    "        self.pos_encoding = positional_encoding(self.n_timesteps, self.d_model)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            # attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
    "            # attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x\n",
    "    \n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    # return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "    return pos_encoding\n",
    "\n",
    "\n",
    "\n",
    "class Transformer(tf.keras.Model):\n",
    "    #Initilaize Transformer and set class variables\n",
    "    \"\"\"\n",
    "    n_target_features: number of features to predict\n",
    "    num_layers: number of layers \n",
    "    d_model: dimensionality of the representations used as input to the multi-head attention, \n",
    "    num_heads: number of attentio heads, \n",
    "    dff: internal dimensionality of the FeedForward layer, \n",
    "    rate: Dropout rate\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 n_target_features, \n",
    "                 num_encoder_layers=4, \n",
    "                 num_decoder_layers=4,\n",
    "                 d_model=128, \n",
    "                 num_heads=8, \n",
    "                 dff=512, \n",
    "                 rate=dropout_rate,\n",
    "                ):\n",
    "        super(Transformer, self).__init__()\n",
    "        #number of predicted values\n",
    "        self.n_target_features = n_target_features\n",
    "        #Initilaize Encoder\n",
    "        self.tokenizer = Encoder(\n",
    "            num_encoder_layers, \n",
    "            d_model, \n",
    "            num_heads, \n",
    "            dff, \n",
    "            rate\n",
    "        )\n",
    "        #Initiliaze Decoder\n",
    "        self.decoder = Decoder(\n",
    "            num_decoder_layers, \n",
    "            d_model, \n",
    "            num_heads, \n",
    "            dff, \n",
    "            rate\n",
    "        )\n",
    "        #Dense layers to project the input vectors before using them.\n",
    "        self.final_layer = tf.keras.layers.Dense(self.n_target_features)\n",
    "    \n",
    "    \"\"\"\n",
    "    inp: batch_size\n",
    "    tar: batch_size\n",
    "    training: inp_seq_len\n",
    "    \"\"\"\n",
    "    def call(self, inp, tar, training):\n",
    "\n",
    "        look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "        \n",
    "        enc_output = self.tokenizer(inp, training, None)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output = self.decoder(tar, enc_output, training, look_ahead_mask, None)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ce9bcb",
   "metadata": {},
   "source": [
    "### Setup Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bfa9b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rs1044\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer Orthogonal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function MultiHeadAttention.split_heads at 0x000002830C055F30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function MultiHeadAttention.split_heads at 0x000002830C055E10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "xformer = Transformer(\n",
    "    n_target_features=3,\n",
    "    num_encoder_layers = num_encoder_layers, \n",
    "    num_decoder_layers = num_decoder_layers,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    d_model=d_model, \n",
    "    rate=dropout_rate\n",
    ")\n",
    "pred = xformer(\n",
    "    inp=tf.random.normal((1,24,4)),\n",
    "    tar=tf.random.normal((1,6,3)),\n",
    "    training=False\n",
    ")\n",
    "# xformer.load_weights(\"xformer.h5\")\n",
    "#print(pred.shape)\n",
    "#xformer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c71e5c",
   "metadata": {},
   "source": [
    "### Set Up GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f22d2660",
   "metadata": {},
   "outputs": [],
   "source": [
    "in1 = Input((24,4))\n",
    "gru1 = GRU(128)(in1)\n",
    "gru2 = RepeatVector(6)(gru1)\n",
    "gru2 = GRU(128,return_sequences=True)(gru2)\n",
    "gru2 = TimeDistributed(Dense(3))(gru2)\n",
    "\n",
    "model = Model(in1,gru2)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0a16e3",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74a835a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "\n",
    "\n",
    "# Use the Adam optimizer with a custom learning rate scheduler according to the formula in the original Transformer paper.\n",
    "#lrate = d_model^-0.5 * min(step_num^-0.5, step_num*warmup_steps^-1.5)\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "#Adam optimization is a stochastic gradient descent method that is based on \n",
    "#adaptive estimation of first-order and second-order moments.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,epsilon=1e-9)\n",
    "\n",
    "#learning_rate: Defaults to 0.001\n",
    "optimizer2 = tf.keras.optimizers.Adam(beta_1=0.9, beta_2=0.98,epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93fadcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0| Transformer:3.875502586364746\n",
      "epoch 1| Transformer:2.758338451385498\n",
      "epoch 2| Transformer:1.418770670890808\n",
      "epoch 3| Transformer:0.5570831298828125\n",
      "epoch 4| Transformer:0.6359307765960693\n",
      "epoch 5| Transformer:0.4600798785686493\n",
      "epoch 6| Transformer:0.4254978895187378\n",
      "epoch 7| Transformer:0.38603463768959045\n",
      "epoch 8| Transformer:0.3219052851200104\n",
      "epoch 9| Transformer:0.28768131136894226\n",
      "epoch 10| Transformer:0.26121705770492554\n",
      "epoch 11| Transformer:0.24930308759212494\n",
      "epoch 12| Transformer:0.22067829966545105\n",
      "epoch 13| Transformer:0.2096727341413498\n",
      "epoch 14| Transformer:0.18230366706848145\n",
      "epoch 15| Transformer:0.16613611578941345\n",
      "epoch 16| Transformer:0.16186116635799408\n",
      "epoch 17| Transformer:0.1484900861978531\n",
      "epoch 18| Transformer:0.13627570867538452\n",
      "epoch 19| Transformer:0.1291346698999405\n"
     ]
    }
   ],
   "source": [
    "len_data = sum(1 for _ in input_dataset)\n",
    "#For each Epoch\n",
    "for e in range(epochs):\n",
    "    #For every batch in the data_batch\n",
    "    for i,batch in enumerate(zip(input_dataset, target_dataset)):\n",
    "        #if not last batch\n",
    "        if i<len_data-1:\n",
    "            #take the ith input and darget batch\n",
    "            in1, tar = batch\n",
    "            \n",
    "            #Create a tensor with all elements set to one in dimension 256, 1, 3 and scale it with -0.1\n",
    "            tar_inp = tf.ones((256,1,3))*-0.1\n",
    "            tar_inp = tf.concat([tar_inp,tar[:, :-1]],axis=1)\n",
    "            tar_real = tar[:, 1:]\n",
    "            \"\"\"\n",
    "            #Computes the gradient using operations recorded in context of this tape.\n",
    "            #Example\n",
    "            with tf.GradientTape() as t1:\n",
    "                loss1_result= loss1(true, pred)\n",
    "            grads1 = t1.gradient(loss1_result, var_list1)\n",
    "            \"\"\"\n",
    "            with tf.GradientTape() as tape:\n",
    "                #Make predictions with input batch (in1), output\n",
    "                predictions = xformer(in1, tar_inp,True)\n",
    "                #Calculate Mean Squared Error (MSE)\n",
    "                loss = tf.reduce_mean(tf.square(tar_real-predictions[:,:-1]))\n",
    "            \"\"\"\n",
    "            #Calculate gradient using loss as function and trainable_variables as input\n",
    "            x = tf.ragged.constant([[1.0, 2.0], [3.0]])\n",
    "            with tf.GradientTape() as g:\n",
    "              g.watch(x)\n",
    "              y = x * x\n",
    "            g.gradient(y, x)\n",
    "            [[2.0, 4.0], [6.0]]\n",
    "            \"\"\"\n",
    "            gradients = tape.gradient(loss, xformer.trainable_variables)\n",
    "            #Apply optimizer\n",
    "            optimizer.apply_gradients(zip(gradients, xformer.trainable_variables))\n",
    "            \n",
    "            \"\"\"\n",
    "            #Same for GRU\n",
    "            with tf.GradientTape() as tape:\n",
    "                pred2 = model(in1)\n",
    "                loss2 = tf.reduce_mean(tf.square(tar-pred2))\n",
    "            gradients = tape.gradient(loss2, model.trainable_variables)\n",
    "            optimizer2.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "            \"\"\"\n",
    "\n",
    "    \n",
    "    print(f\"epoch {e}| Transformer:{loss.numpy()}\")\n",
    "    #print(f\"epoch {e}| Transformer:{loss.numpy()} | GRU:{loss2.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "709801a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inp):\n",
    "    \n",
    "    inp = inp.reshape(-1,24,4)\n",
    "#     inp = tf.reshape(inp,(-1,24,4))\n",
    "    n_batch = inp.shape[0]\n",
    "    start = np.ones((n_batch,1,3))*-0.1\n",
    "    \n",
    "    for i in range(6):\n",
    "        \n",
    "        pred = xformer(inp,start,False)\n",
    "        pred = np.expand_dims(pred[:,-1,:],0)\n",
    "        start = np.concatenate([start,pred],axis=1)\n",
    "#         print(start.shape)\n",
    "        \n",
    "    return start[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b84ddeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = timeseries_dataset_from_array(X_test,None, sequence_length=sample_length,batch_size=1, sequence_stride=sample_length)\n",
    "y_test = timeseries_dataset_from_array(y_test, None, sequence_length=6,batch_size=1, sequence_stride=sample_length)\n",
    "x_test = list(x_test.as_numpy_iterator())\n",
    "y_test = list(y_test.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7eb84e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test2 = np.asarray(x_test).reshape(-1,24,4)\n",
    "y_test2 = np.asarray(y_test).reshape(-1,6,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed9c5588",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_xform = [predict(x) for x in x_test2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d0c996a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.04158305031998204, 0.094803944)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_xform = np.mean([(y_true-y_pred)**2 for y_true,y_pred in zip(y_test2,preds_xform)])\n",
    "\n",
    "pred_gru = model(x_test2)\n",
    "err_gru = np.mean((pred_gru-y_test2)**2)\n",
    "\n",
    "err_xform,err_gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26f6e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6a79a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d01724c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
